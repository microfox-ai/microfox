## Function: `streamText`

Streams text generations from a language model. This function is ideal for interactive applications like chatbots and real-time text generation, allowing you to process and display text as it's generated by the model. It also supports tool calling for enhanced functionality.

**Purpose:**

Enables streaming text generation from language models, facilitating interactive experiences and real-time applications.

**Parameters:**

- `model`: **LanguageModel** (required)
  - The language model to use for text generation. Example: `openai('gpt-4-turbo')`. This parameter expects a LanguageModel object, which is typically created using provider-specific functions like `openai()`.
- `system` (optional): **string**
  - The system-level instruction that sets the behavior of the model. This prompt guides the overall tone and style of the generated text.
- `prompt` (optional): **string**
  - The input prompt that triggers the text generation. This is the specific text or question you want the model to respond to.
- `messages` (optional): **array<SystemMessage | UserMessage | AssistantMessage | ToolMessage>**
  - An array of messages representing a conversation history. This allows for context-aware responses. Automatically converts UI messages from the `useChat` hook. Each message object can be one of the following types:
    - `SystemMessage`:
      - `role`: **string** - Always 'system'.
      - `content`: **string** - The system message content.
    - `UserMessage`:
      - `role`: **string** - Always 'user'.
      - `content`: **string | array<TextPart | ImagePart>** - The user message content.
        - `TextPart`:
          - `type`: **string** - Always 'text'.
          - `text`: **string** - The text content.
        - `ImagePart`:
          - `type`: **string** - Always 'image'.
          - `image`: **string | Uint8Array | Buffer | ArrayBuffer | URL** - The image data. Strings can be base64 encoded content, base64 data URLs, or http(s) URLs.
          - `mediaType`: **string** (optional) - The media type of the image.
    - `AssistantMessage`:
      - `role`: **string** - Always 'assistant'.
      - `content`: **string | array<TextPart | ToolCallPart>** - The assistant message content.
        - `TextPart`: As described above.
        - `ToolCallPart`:
          - `type`: **string** - Always 'tool-call'.
          - `toolCallId`: **string** - The ID of the tool call.
          - `toolName`: **string** - The name of the tool.
          - `args`: **object** - Arguments for the tool call (based on the tool's Zod schema).
    - `ToolMessage`:
      - `role`: **string** - Always 'tool'.
      - `content`: **array<{ type: 'tool-result'; toolCallId: string; toolName: string; result: unknown; isError?: boolean; }>** - The tool result content.
- Many other optional parameters exist, including `toolChoice`, `maxTokens`, `temperature`, `topP`, `topK`, `presencePenalty`, `frequencyPenalty`, `stopSequences`, `seed`, `maxRetries`, `abortSignal`, `headers`, and `onFinish`. These parameters offer fine-grained control over the text generation process.

**Return Value:**

An object containing the following properties:

- `textStream`: **AsyncIterable<string> & ReadableStream<string>** - A stream of generated text deltas.
- `toolCallsStream`: Stream of tool calls.
- `toolResultsStream`: Stream of tool results.
- `objectStream`: Stream of objects when using `experimental_streamObject`.
- `fullStream`: A stream of all events, including text deltas, tool calls, and tool results.
- Several promise-based properties that resolve when the generation is complete: `finishReason`, `usage`, `warnings`, `rawResponse`, `text`, `toolCalls`, and `toolResults`. These provide comprehensive information about the generation process and results.
- `experimental_streamObject`: A helper function to stream objects.

**Examples:**

```typescript
import { openai } from '@ai-sdk/openai';
import { streamText, tool } from 'ai';
import { z } from 'zod';

// Example 1: Basic usage
const { textStream } = streamText({
  model: openai('gpt-4-turbo'),
  prompt: 'Write a short story about a robot learning to love.',
});

for await (const textPart of textStream) {
  process.stdout.write(textPart);
}

// Example 2: Using system prompt and messages
const { textStream: textStream2 } = streamText({
  model: openai('gpt-3.5-turbo'),
  system: 'You are a helpful assistant.',
  messages: [
    { role: 'user', content: 'What is the capital of France?' },
    { role: 'assistant', content: 'Paris.' },
    { role: 'user', content: 'And what is its population?' },
  ],
});

for await (const textPart of textStream2) {
  process.stdout.write(textPart);
}

// Example 3: Tool calling (requires defining and registering tools)
const { textStream: textStream3, toolResults } = await streamText({
  model: openai('gpt-4-turbo'),
  prompt: 'What is the weather in San Francisco?',
  tools: {
    getWeather: tool({
      description: 'Get the current weather in a given location.',
      parameters: z.object({
        city: z.string().describe('The city to get the weather for.'),
      }),
      execute: async ({ city }) => ({
        city,
        temperature: Math.floor(Math.random() * 30),
      }),
    }),
  },
});

for await (const delta of textStream3) {
  process.stdout.write(delta);
}
```
