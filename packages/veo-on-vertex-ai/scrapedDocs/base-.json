{
  "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/veo-video-generation",
  "content": "Skip to main content\nSign in\nContact Us\nStart free\nDocumentation\nGuides\nAPI reference\nVertex AI Cookbook\nPrompt gallery\nResources\nFAQ\nTechnology areas\nCross-product tools\nRelated sites\nStart free\nAPI reference\nGemini API\nEmbeddings API\nImagen API\nVeo video generation API\nLyria music generation API\nBatch prediction API\nTuning API\nGen AI Evaluation API\nRAG API\nCountTokens API\nAgent Engine API\nMedLM API\nREST and RPC reference\nVertex AI in express mode\nREST\nRPC\nGoogle Gen AI SDK\nOverview\nPython\nGo\nJava\nNode.js\nVertex AI SDK\nOverview\nPython\nNode.js\nJava\nGo\nC#\nAgent Development Kit (ADK)\nOverview\nStarting April 29, 2025, Gemini 1.5 Pro and Gemini 1.5 Flash models are not available in projects that have no prior usage of these models, including new projects. For details, see Model versions and lifecycle.\nGenerative AI on Vertex AI \nDocumentation \nAPI reference\nWas this helpful?\nSend feedback\nVeo on Vertex AI API\nbookmark_border\nOn this page\nSupported Models\nHTTP request\nSample request\nText-to-video generation request\nImage-to-video generation request\nPoll the status of the video generation long-running operation\nResponse body (generate video request)\nSample response (generate video request)\n\nVeo is the name of the model that supports video generation. Veo generates a video from a text prompt or an image prompt that you provide.\n\nTo explore this model in the console, see the Video Generation model card in the Model Garden.\n\nTry Veo on Vertex AI (Vertex AI Studio)\n\nTry Veo in a Colab\n\nRequest access: Advanced features & Veo waitlist\n\nSupported Models\n\nVeo API supports the following models:\n\nveo-2.0-generate-001\nveo-3.0-generate-preview (Preview)\nHTTP request\ncurl -X POST \\\n  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n  -H \"Content-Type: application/json\" \\\nhttps://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/google/models/MODEL_ID:predictLongRunning \\\n\n-d '{\n  \"instances\": [\n    {\n      \"prompt\": string,\n      // Optional. An image to guide video generation.\n      \"image\": {\n        // Union field can be only one of the following:\n        \"bytesBase64Encoded\": string,\n        \"gcsUri\": string,\n        // End of list of possible types for union field.\n        \"mimeType\": string\n      }\n    }\n  ],\n  \"parameters\": {\n    \"aspectRatio\": string,\n    \"negativePrompt\": string,\n    \"personGeneration\": string,\n    \"sampleCount\": integer,\n    \"seed\": uint32,\n    \"storageUri\": string,\n    \"durationSeconds\": integer,\n    \"enhancePrompt\": boolean\n  }\n}'\n\n\nUse the following parameters for the Veo model. For more information, see Generate videos using text and image prompts using Veo.\n\nParameter\n\nprompt\n\nstring\n\nRequired for text-to-video.\nOptional if an input image prompt is provided (image-to-video).\n\nA text string to guide the first eight seconds in the video. For example:\n\nA fast-tracking shot through a bustling dystopian sprawl with bright neon signs, flying cars and mist, night, lens flare, volumetric lighting\nA neon hologram of a car driving at top speed, speed of light, cinematic, incredible details, volumetric lighting\nMany spotted jellyfish pulsating under water. Their bodies are transparent and glowing in deep ocean\nextreme close-up with a shallow depth of field of a puddle in a street. reflecting a busy futuristic Tokyo city with bright neon signs, night, lens flare\nTimelapse of the northern lights dancing across the Arctic sky, stars twinkling, snow-covered landscape\nA lone cowboy rides his horse across an open plain at beautiful sunset, soft light, warm colors\n\nimage\n\nstring\n\nRequired for image-to-video.\nOptional if a text prompt is provided (text-to-video).\n\nAn input image for guiding video generation. We recommend an image that is 1280 x 720 pixels or 720 x 1280 pixels.\n\nOne of the following:\n\nA Base64-encoded image byte string\nA Cloud Storage bucket URI\n\nIf the aspect ratio of the image is different, the image is cropped using a center crop tool.\n\nIf the aspect ratio of the image is the same but the resolution is larger, the image is resized.\n\ndurationSeconds\n\ninteger\n\nRequired. The length of video files that you want to generate.\n\nThe following are the accepted values for each model:\n\nveo-2.0-generate-001: 5-8. The default is 8.\nveo-3.0-generate-preview: 8.\nnegativePrompt\n\nstring\n\nOptional. A text string that describes anything you want to discourage the model from generating. For example:\n\noverhead lighting, bright colors\npeople, animals\nmultiple cars, wind\nenhancePrompt\n\nboolean\n\nOptional. Use Gemini to enhance your prompts. Accepted values are true or false. The default value is true.\n\nseed\n\nuint32\n\nOptional. A number to request to make generated videos deterministic. Adding a seed number with your request without changing other parameters will cause the model to produce the same videos.\n\nThe accepted range is 0-4,294,967,295.\n\nstorageURI\n\nstring\n\nOptional. A Cloud Storage bucket URI to store the output video, in the format gs://BUCKET_NAME/SUBDIRECTORY. If a Cloud Storage bucket isn't provided, base64-encoded video bytes are returned in the response.\n\nsampleCount\n\nint\n\nOptional. The number of output images requested. Accepted values are 1-4.\n\naspectRatio\n\nstring\n\nOptional. Defines the aspect ratio of the generated video. One of the following:\n\n16:9 (default, landscape)\n\n9:16 (portrait)\n\nNote:The 9:16 aspect ratio isn't supported by veo-3.0-generate-preview.\npersonGeneration\n\nstring\n\nOptional. The safety setting that controls whether people or face generation is allowed. One of the following:\n\nallow_adult (default value): allow generation of adults only\ndont_allow: disallows inclusion of people/faces in images\ngenerateAudio\n\nboolean\n\nRequired for veo-3.0-generate-preview. Generate audio for the video. Accepted values are true or false.\n\ngenerateAudio isn't supported by veo-2.0-generate-001.\n\nSample request\n\nUse the following requests to send a text-to-video request or an image-to-video request:\n\nText-to-video generation request\nREST\n\nTo test a text prompt by using the Vertex AI Veo API, send a POST request to the publisher model endpoint.\n\nBefore using any of the request data, make the following replacements:\n\nPROJECT_ID: Your Google Cloud project ID.\nMODEL_ID: The model ID to use. Available values:\nveo-2.0-generate-001 (GA)\nveo-3.0-generate-preview (Preview)\nTEXT_PROMPT: The text prompt used to guide video generation.\nOUTPUT_STORAGE_URI: Optional: The Cloud Storage bucket to store the output videos. If not provided, video bytes are returned in the response. For example: gs://video-bucket/output/.\nRESPONSE_COUNT: The number of video files you want to generate. Accepted integer values: 1-4.\nDURATION: The length of video files that you want to generate. Accepted integer values are 5-8.\n\nAdditional optional parameters\n\nHTTP method and URL:\n\nPOST https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:predictLongRunning\n\nRequest JSON body:\n\n{\n  \"instances\": [\n    {\n      \"prompt\": \"TEXT_PROMPT\"\n    }\n  ],\n  \"parameters\": {\n    \"storageUri\": \"OUTPUT_STORAGE_URI\",\n    \"sampleCount\": \"RESPONSE_COUNT\"\n  }\n}\n\n\nTo send your request, choose one of these options:\n\ncurl\nPowerShell\nNote: The following command assumes that you have logged in to the gcloud CLI with your user account by running gcloud init or gcloud auth login , or by using Cloud Shell, which automatically logs you into the gcloud CLI . You can check the currently active account by running gcloud auth list.\n\nSave the request body in a file named request.json, and execute the following command:\n\ncurl -X POST \\\n     -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n     -H \"Content-Type: application/json; charset=utf-8\" \\\n     -d @request.json \\\n     \"https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:predictLongRunning\"\nThis request returns a full operation name with a unique operation ID. Use this full operation name to poll that status of the video generation request.\n{\n  \"name\": \"projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID/operations/a1b07c8e-7b5a-4aba-bb34-3e1ccb8afcc8\"\n}\n\n\nImage-to-video generation request\nREST\n\nTo test a text prompt by using the Vertex AI Veo API, send a POST request to the publisher model endpoint.\n\nBefore using any of the request data, make the following replacements:\n\nPROJECT_ID: Your Google Cloud project ID.\nMODEL_ID: The model ID to use. Available values:\nveo-2.0-generate-001 (GA)\nveo-3.0-generate-preview (Preview)\nTEXT_PROMPT: The text prompt used to guide video generation.\nINPUT_IMAGE: Base64-encoded bytes string representing the input image. To ensure quality, the input image should be 720p or higher (1280 x 720 pixels) and have a 16:9 or 9:16 aspect ratio. Images of other aspect ratios or sizes may be resized or centrally cropped during the upload process.\nMIME_TYPE: The MIME type of the input image. Only the images of the following MIME types are supported: image/jpeg or image/png.\nOUTPUT_STORAGE_URI: Optional: The Cloud Storage bucket to store the output videos. If not provided, video bytes are returned in the response. For example: gs://video-bucket/output/.\nRESPONSE_COUNT: The number of video files you want to generate. Accepted integer values: 1-4.\nDURATION: The length of video files that you want to generate. Accepted integer values are 5-8.\n\nAdditional optional parameters\n\nHTTP method and URL:\n\nPOST https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:predictLongRunning\n\nRequest JSON body:\n\n{\n  \"instances\": [\n    {\n      \"prompt\": \"TEXT_PROMPT\",\n      \"image\": {\n        \"bytesBase64Encoded\": \"INPUT_IMAGE\",\n        \"mimeType\": \"MIME_TYPE\"\n      }\n    }\n  ],\n  \"parameters\": {\n    \"storageUri\": \"OUTPUT_STORAGE_URI\",\n    \"sampleCount\": RESPONSE_COUNT\n  }\n}\n\n\nTo send your request, choose one of these options:\n\ncurl\nPowerShell\nNote: The following command assumes that you have logged in to the gcloud CLI with your user account by running gcloud init or gcloud auth login , or by using Cloud Shell, which automatically logs you into the gcloud CLI . You can check the currently active account by running gcloud auth list.\n\nSave the request body in a file named request.json, and execute the following command:\n\ncurl -X POST \\\n     -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n     -H \"Content-Type: application/json; charset=utf-8\" \\\n     -d @request.json \\\n     \"https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:predictLongRunning\"\nThis request returns a full operation name with a unique operation ID. Use this full operation name to poll that status of the video generation request.\n{\n  \"name\": \"projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID/operations/a1b07c8e-7b5a-4aba-bb34-3e1ccb8afcc8\"\n}\n\n\nPoll the status of the video generation long-running operation\n\nCheck the status of the video generation long-running operation.\n\nREST\n\nBefore using any of the request data, make the following replacements:\n\nPROJECT_ID: Your Google Cloud project ID.\nMODEL_ID: The model ID to use. Available values:\nveo-2.0-generate-001 (GA)\nveo-3.0-generate-preview (Preview)\nOPERATION_ID: The unique operation ID returned in the original generate video request.\n\nHTTP method and URL:\n\nPOST https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:fetchPredictOperation\n\nRequest JSON body:\n\n{\n  \"operationName\": \"projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID/operations/OPERATION_ID\"\n}\n\n\nTo send your request, choose one of these options:\n\ncurl\nPowerShell\nNote: The following command assumes that you have logged in to the gcloud CLI with your user account by running gcloud init or gcloud auth login , or by using Cloud Shell, which automatically logs you into the gcloud CLI . You can check the currently active account by running gcloud auth list.\n\nSave the request body in a file named request.json, and execute the following command:\n\ncurl -X POST \\\n     -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n     -H \"Content-Type: application/json; charset=utf-8\" \\\n     -d @request.json \\\n     \"https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:fetchPredictOperation\"\nThis request returns information about the operation, including if the operation is still running or is done.\nResponse\n\nResponse body (generate video request)\n\nSending a text-to-video or image-to-video request returns the following response:\n\n{\n  \"name\": string\n}\n\nResponse element\tDescription\nname\tThe full operation name of the long-running operation that begins after a video generation request is sent.\nSample response (generate video request)\n{\n  \"name\": \"projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID/operations/OPERATION_ID\"\n}\n\nResponse body (poll long-running operation)\n\nPolling the status of the original video generation long-running operation returns the following response:\n\n{\n   \"name\": string,\n   \"done\": boolean,\n   \"response\":{\n      \"@type\":\"type.googleapis.com/cloud.ai.large_models.vision.GenerateVideoResponse\",\n      \"generatedSamples\":[\n         {\n            \"video\":\n            {\n               \"uri\": string,\n               \"encoding\": string\n            }\n         },\n         {\n            \"video\":\n            {\n               \"uri\": string,\n               \"encoding\": string\n            }\n         },\n         {\n            \"video\":\n            {\n               \"uri\": string,\n               \"encoding\": string\n            }\n         },\n         {\n            \"video\":\n            {\n               \"uri\": string,\n               \"encoding\": string\n            }\n         },\n      ]\n   }\n}\n\nResponse element\tDescription\nname\tThe full operation name of the long-running operation that begins after a video generation request is sent.\ndone\tA boolean value that indicates whether the operation is complete.\nresponse\tThe response body of the long-running operation.\ngeneratedSamples\tAn array of the generated video sample objects.\nvideo\tThe generated video.\nuri\tThe Cloud Storage URI of the generated video.\nencoding\tThe video encoding type.\nSample response (poll long-running operation)\n{\n   \"name\": \"projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID/operations/OPERATION_ID\",\n   \"done\":true,\n   \"response\":{\n      \"@type\":\"type.googleapis.com/cloud.ai.large_models.vision.GenerateVideoResponse\",\n      \"generatedSamples\":[\n         {\n            \"video\":{\n               \"uri\":\"gs://STORAGE_BUCKET/TIMESTAMPED_SUBDIRECTORY/sample_0.mp4\",\n               \"encoding\":\"video/mp4\"\n            }\n         },\n         {\n            \"video\":{\n               \"uri\":\"gs://STORAGE_BUCKET/TIMESTAMPED_SUBDIRECTORY/sample_1.mp4\",\n               \"encoding\":\"video/mp4\"\n            }\n         },\n         {\n            \"video\":{\n               \"uri\":\"gs://STORAGE_BUCKET/TIMESTAMPED_SUBDIRECTORY/sample_2.mp4\",\n               \"encoding\":\"video/mp4\"\n            }\n         },\n         {\n            \"video\":{\n               \"uri\":\"gs://STORAGE_BUCKET/TIMESTAMPED_SUBDIRECTORY/sample_3.mp4\",\n               \"encoding\":\"video/mp4\"\n            }\n         }\n      ]\n   }\n}\n\nMore information\nFor more information about using Veo on Vertex AI, see Generate videos using text and image prompts using Veo.\nWhat's next\nRead Google DeepMind's information on the Veo model.\nRead the blog post \"Veo and Imagen 3: Announcing new video and image generation models on Vertex AI\".\nRead the blog post \"New generative media models and tools, built with and for creators\".\nWas this helpful?\nSend feedback\n\nExcept as otherwise noted, the content of this page is licensed under the Creative Commons Attribution 4.0 License, and code samples are licensed under the Apache 2.0 License. For details, see the Google Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.\n\nLast updated 2025-06-21 UTC.\n\nWhy Google\nChoosing Google Cloud\nTrust and security\nModern Infrastructure Cloud\nMulticloud\nGlobal infrastructure\nCustomers and case studies\nAnalyst reports\nWhitepapers\nProducts and pricing\nSee all products\nSee all solutions\nGoogle Cloud for Startups\nGoogle Cloud Marketplace\nGoogle Cloud pricing\nContact sales\nSupport\nGoogle Cloud Community\nSupport\nRelease Notes\nSystem status\nResources\nGitHub\nGetting Started with Google Cloud\nGoogle Cloud documentation\nCode samples\nCloud Architecture Center\nTraining and Certification\nDeveloper Center\nEngage\nBlog\nEvents\nX (Twitter)\nGoogle Cloud on YouTube\nGoogle Cloud Tech on YouTube\nBecome a Partner\nGoogle Cloud Affiliate Program\nPress Corner\nAbout Google\nPrivacy\nSite terms\nGoogle Cloud terms\nOur third decade of climate action: join us\nSign up for the Google Cloud newsletter\nSubscribe",
  "updatedAt": "2025-06-22T21:10:59.576Z"
}